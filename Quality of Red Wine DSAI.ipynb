{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2a32aba",
   "metadata": {},
   "source": [
    "## Import Basic Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a94df3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed93a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "sb.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93634e7",
   "metadata": {},
   "source": [
    "## Import Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f99b5f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainData = pd.read_csv('winequality-red.csv')\n",
    "trainData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d8bc0f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainData.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9c9498",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(trainData) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b98302",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData.shape #data size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7fda42",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainData.isnull().sum() #check for missing values "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2431be73",
   "metadata": {},
   "source": [
    "## Data for Max Quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22dc7b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "count = 0\n",
    "while i < 1599:   #loop to count number of wine with max quality\n",
    "    if trainData['quality'][i]==8:\n",
    "        count+=1\n",
    "    i+=1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46431b03",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "maxQuality = trainData[(trainData['quality']==8)] #data for wine with max quality\n",
    "maxQuality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1861460",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "maxQuality.describe() #statistics for factors for max quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59acf8b2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(12, figsize=(10, 50))  #visualisation to see which value of factors produce max quality\n",
    "\n",
    "count = 0\n",
    "for var in trainData:\n",
    "    sb.histplot(data = maxQuality[var], ax = axes[count])\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796c57d2",
   "metadata": {},
   "source": [
    "## Data Visualisation and Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02d4e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plt.figure(figsize=(16, 8))\n",
    "sb.boxplot(data = trainData, orient = \"h\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73722a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(12, 3, figsize=(30, 50))\n",
    "\n",
    "count = 0\n",
    "for var in trainData:\n",
    "    sb.boxplot(data = trainData[var], orient = \"h\", ax = axes[count,0])\n",
    "    sb.histplot(data = trainData[var], ax = axes[count,1])\n",
    "    sb.violinplot(data = trainData[var], orient = \"h\", ax = axes[count,2])\n",
    "    count += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f75479a",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plt.figure(figsize=(12, 12))\n",
    "sb.heatmap(trainData.corr(), vmin = -1, vmax = 1, annot = True, fmt = \".2f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf8ce59",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData[['fixed acidity',\n",
    " 'volatile acidity',\n",
    " 'citric acid',\n",
    " 'residual sugar',\n",
    " 'chlorides',\n",
    " 'free sulfur dioxide',\n",
    " 'total sulfur dioxide',\n",
    " 'density',\n",
    " 'pH',\n",
    " 'sulphates',\n",
    " 'alcohol',\n",
    " 'quality']].corr()['quality'][:]   #list of corr of factors against quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e38e23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c399e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = ['fixed acidity',\n",
    " 'volatile acidity',\n",
    " 'citric acid',\n",
    " 'residual sugar',\n",
    " 'chlorides',\n",
    " 'free sulfur dioxide',\n",
    " 'total sulfur dioxide',\n",
    " 'density',\n",
    " 'pH',\n",
    " 'sulphates',\n",
    " 'alcohol',\n",
    " 'quality']\n",
    "\n",
    "for i in x:  #range of +-0.20 to choose factors \n",
    "    if trainData[i].corr(trainData['quality']) > 0.20 or trainData[i].corr(trainData['quality']) < -0.20:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89df844",
   "metadata": {},
   "outputs": [],
   "source": [
    "finalData = trainData[['volatile acidity', 'citric acid', 'sulphates', 'alcohol', 'quality']] #factors chosen for final data\n",
    "finalData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488de839",
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.pairplot(data = finalData) #visualisation of final data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676a259c",
   "metadata": {},
   "source": [
    "### 4.3 Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16957612",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import essential models and functions from sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Extract Response and Predictors\n",
    "y = pd.DataFrame(finalData[\"quality\"])\n",
    "X = pd.DataFrame(finalData[[\"volatile acidity\", \"citric acid\", \"sulphates\",\"alcohol\"]])\n",
    "\n",
    "# Split the Dataset into Train and Test\n",
    "# 25% of data is used for testing dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25)\n",
    "\n",
    "# Check the sample sizes\n",
    "print(\"Predictor Train Set :\", X_train.shape, \"Predictor Test Set :\", X_test.shape)\n",
    "print(\"Response Train Set :\", y_train.shape, \"Response Test Set :\", y_test.shape)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2eee3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.fit_transform(X_test)\n",
    "\n",
    "# Logistic Regression using Train Data\n",
    "logreg = LogisticRegression()         # create the Logistic regression object\n",
    "logreg.fit(X_train, y_train.values.ravel())        # train the Logistic regression model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6174047c",
   "metadata": {},
   "source": [
    "#### Accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5beb52af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicting cross validation score \n",
    "#cv_lr = cross_val_score(estimator = Lr, X = X_train, y = y_train, cv = 10)\n",
    "#print(\"CV: \", cv_lr.mean())\n",
    "\n",
    "y_train_pred = logreg.predict(X_train)\n",
    "accuracy_train = accuracy_score(y_train,y_train_pred)\n",
    "print(\"Training set: \", accuracy_train)\n",
    "\n",
    "y_test_pred = logreg.predict(X_test)\n",
    "accuracy_test = accuracy_score(y_test,y_test_pred)\n",
    "print(\"Test set: \", accuracy_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4a16d2",
   "metadata": {},
   "source": [
    "### 4.4 K-Nearest Neighbour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe9ab18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import essential models and functions from sklearn\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Extract Response and Predictors\n",
    "y = pd.DataFrame(finalData[\"quality\"])\n",
    "X = pd.DataFrame(finalData[[\"volatile acidity\", \"citric acid\", \"sulphates\",\"alcohol\"]])\n",
    "\n",
    "# Split the Dataset into Train and Test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25)\n",
    "\n",
    "# Check the sample sizes\n",
    "print(\"Predictor Train Set :\", X_train.shape, \"Predictor Test Set :\", X_test.shape)\n",
    "print(\"Response Train Set :\", y_train.shape, \"Response Test Set :\", y_test.shape)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1998ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train,y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70a5b67",
   "metadata": {},
   "source": [
    "#### Accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dbf9bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicting cross validation score \n",
    "#cv_knn = cross_val_score(estimator = knn, X = X_train, y = y_train, cv = 10)\n",
    "#print(\"CV: \", cv_knn.mean())\n",
    "\n",
    "y_train_pred = knn.predict(X_train)\n",
    "accuracy_train = accuracy_score(y_train,y_train_pred)\n",
    "print(\"Training set: \", accuracy_train)\n",
    "\n",
    "y_test_pred = knn.predict(X_test)\n",
    "accuracy_test = accuracy_score(y_test,y_test_pred)\n",
    "print(\"Test set: \", accuracy_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814ef271",
   "metadata": {},
   "outputs": [],
   "source": [
    "finalData['quality'].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14bc64ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "finalData['quality']=finalData['quality'].astype('Int64')\n",
    "print(finalData['quality'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8769fff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "finalData['quality'] = pd.cut(finalData['quality'],bins=[0,6.5,8],labels=['poor','good'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d268c2fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "finalData['quality'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac33bc33",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = finalData.drop('quality', axis = 1)\n",
    "y = finalData['quality']\n",
    "y=y.astype('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc15850",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.25)\n",
    "dectree = DecisionTreeClassifier(max_depth = 2)\n",
    "dectree.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31bca2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import plot_tree\n",
    "fig, ax = plt.subplots(figsize=(12, 12))\n",
    "out = plot_tree(dectree, \n",
    "          feature_names = x_train.columns,\n",
    "          class_names = [str(x) for x in dectree.classes_],\n",
    "          filled=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196c1721",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree using Train Data\n",
    "dectree = DecisionTreeClassifier(max_depth = 3)  # create the decision tree object\n",
    "dectree.fit(x_train, y_train)                    # train the decision tree model\n",
    "\n",
    "# Predict Response corresponding to Predictors\n",
    "y_train_pred = dectree.predict(x_train)\n",
    "y_test_pred = dectree.predict(x_test)\n",
    "\n",
    "# Check the Goodness of Fit (on Train Data)\n",
    "print(\"Goodness of Fit of Model \\tTrain Dataset\")\n",
    "print(\"Classification Accuracy \\t:\", dectree.score(x_train, y_train))\n",
    "print()\n",
    "\n",
    "# Check the Goodness of Fit (on Test Data)\n",
    "print(\"Goodness of Fit of Model \\tTest Dataset\")\n",
    "print(\"Classification Accuracy \\t:\", dectree.score(x_test, y_test))\n",
    "print()\n",
    "\n",
    "# Plot the Confusion Matrix for Train and Test\n",
    "f, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "sb.heatmap(confusion_matrix(y_train, y_train_pred),\n",
    "           annot = True, fmt=\".0f\", annot_kws={\"size\": 18}, ax = axes[0])\n",
    "sb.heatmap(confusion_matrix(y_test, y_test_pred), \n",
    "           annot = True, fmt=\".0f\", annot_kws={\"size\": 18}, ax = axes[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54992c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d88f7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(n_estimators = 200)\n",
    "rfc.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551b1046",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree using Train Data\n",
    "dectree = DecisionTreeClassifier(max_depth = 3)  # create the decision tree object\n",
    "dectree.fit(x_train, y_train)                    # train the decision tree model\n",
    "\n",
    "# Predict Response corresponding to Predictors\n",
    "y_train_pred = dectree.predict(x_train)\n",
    "y_test_pred = dectree.predict(x_test)\n",
    "\n",
    "# Check the Goodness of Fit (on Train Data)\n",
    "print(\"Goodness of Fit of Model \\tTrain Dataset\")\n",
    "print(\"Classification Accuracy \\t:\", dectree.score(x_train, y_train))\n",
    "print()\n",
    "\n",
    "# Check the Goodness of Fit (on Test Data)\n",
    "print(\"Goodness of Fit of Model \\tTest Dataset\")\n",
    "print(\"Classification Accuracy \\t:\", dectree.score(x_test, y_test))\n",
    "print()\n",
    "\n",
    "# Plot the Confusion Matrix for Train and Test\n",
    "f, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "sb.heatmap(confusion_matrix(y_train, y_train_pred),\n",
    "           annot = True, fmt=\".0f\", annot_kws={\"size\": 18}, ax = axes[0])\n",
    "sb.heatmap(confusion_matrix(y_test, y_test_pred), \n",
    "           annot = True, fmt=\".0f\", annot_kws={\"size\": 18}, ax = axes[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa52f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import essential models and functions from sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Extract Response and Predictors\n",
    "y = pd.DataFrame(finalData[\"quality\"])\n",
    "X = pd.DataFrame(finalData[[\"volatile acidity\", \"citric acid\", \"sulphates\",\"alcohol\"]])\n",
    "\n",
    "# Split the Dataset into Train and Test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25)\n",
    "\n",
    "# Check the sample sizes\n",
    "print(\"Predictor Train Set :\", X_train.shape, \"Predictor Test Set :\", X_test.shape)\n",
    "print(\"Response Train Set :\", y_train.shape, \"Response Test Set :\", y_test.shape)\n",
    "print()\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.fit_transform(X_test)\n",
    "\n",
    "# Logistic Regression using Train Data\n",
    "logreg = LogisticRegression()         # create the Logistic regression object\n",
    "logreg.fit(X_train, y_train.values.ravel())        # train the Logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec95f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicting cross validation score \n",
    "#cv_lr = cross_val_score(estimator = Lr, X = X_train, y = y_train, cv = 10)\n",
    "#print(\"CV: \", cv_lr.mean())\n",
    "\n",
    "y_train_pred = logreg.predict(X_train)\n",
    "accuracy_train = accuracy_score(y_train,y_train_pred)\n",
    "print(\"Training set: \", accuracy_train)\n",
    "\n",
    "y_test_pred = logreg.predict(X_test)\n",
    "accuracy_test = accuracy_score(y_test,y_test_pred)\n",
    "print(\"Test set: \", accuracy_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85f944e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import essential models and functions from sklearn\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Extract Response and Predictors\n",
    "y = pd.DataFrame(finalData[\"quality\"])\n",
    "X = pd.DataFrame(finalData[[\"volatile acidity\", \"citric acid\", \"sulphates\",\"alcohol\"]])\n",
    "\n",
    "# Split the Dataset into Train and Test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25)\n",
    "\n",
    "# Check the sample sizes\n",
    "print(\"Predictor Train Set :\", X_train.shape, \"Predictor Test Set :\", X_test.shape)\n",
    "print(\"Response Train Set :\", y_train.shape, \"Response Test Set :\", y_test.shape)\n",
    "print()\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train,y_train.values.ravel())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe2884a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicting cross validation score \n",
    "#cv_knn = cross_val_score(estimator = knn, X = X_train, y = y_train, cv = 10)\n",
    "#print(\"CV: \", cv_knn.mean())\n",
    "\n",
    "y_train_pred = knn.predict(X_train)\n",
    "accuracy_train = accuracy_score(y_train,y_train_pred)\n",
    "print(\"Training set: \", accuracy_train)\n",
    "\n",
    "y_test_pred = knn.predict(X_test)\n",
    "accuracy_test = accuracy_score(y_test,y_test_pred)\n",
    "print(\"Test set: \", accuracy_test)\n",
    "\n",
    "# Plot the Confusion Matrix for Train and Test\n",
    "f, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "sb.heatmap(confusion_matrix(y_train, y_train_pred),\n",
    "           annot = True, fmt=\".0f\", annot_kws={\"size\": 18}, ax = axes[0])\n",
    "sb.heatmap(confusion_matrix(y_test, y_test_pred), \n",
    "           annot = True, fmt=\".0f\", annot_kws={\"size\": 18}, ax = axes[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589c56ee",
   "metadata": {},
   "source": [
    "#### New Knowledge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4211cb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#new knowledge using SVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "svc = SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0514bc30",
   "metadata": {},
   "outputs": [],
   "source": [
    "finalData.columns[finalData.isna().any()]\n",
    "svc.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a88a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = svc.predict(X_train)\n",
    "accuracy_train = accuracy_score(y_train,y_train_pred)\n",
    "print(\"Training set: \", accuracy_train)\n",
    "\n",
    "y_test_pred = svc.predict(X_test)\n",
    "accuracy_test = accuracy_score(y_test,y_test_pred)\n",
    "print(\"Test set: \", accuracy_test)\n",
    "\n",
    "# Plot the Confusion Matrix for Train and Test\n",
    "f, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "sb.heatmap(confusion_matrix(y_train, y_train_pred),\n",
    "           annot = True, fmt=\".0f\", annot_kws={\"size\": 18}, ax = axes[0])\n",
    "sb.heatmap(confusion_matrix(y_test, y_test_pred), \n",
    "           annot = True, fmt=\".0f\", annot_kws={\"size\": 18}, ax = axes[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18910afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "naive = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e178da",
   "metadata": {},
   "outputs": [],
   "source": [
    "naive.fit(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7ead1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = naive.predict(X_train)\n",
    "accuracy_train = accuracy_score(y_train,y_train_pred)\n",
    "print(\"Training set: \", accuracy_train)\n",
    "\n",
    "y_test_pred = svc.predict(X_test)\n",
    "accuracy_test = accuracy_score(y_test,y_test_pred)\n",
    "print(\"Test set: \", accuracy_test)\n",
    "\n",
    "# Plot the Confusion Matrix for Train and Test\n",
    "f, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "sb.heatmap(confusion_matrix(y_train, y_train_pred),\n",
    "           annot = True, fmt=\".0f\", annot_kws={\"size\": 18}, ax = axes[0])\n",
    "sb.heatmap(confusion_matrix(y_test, y_test_pred), \n",
    "           annot = True, fmt=\".0f\", annot_kws={\"size\": 18}, ax = axes[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708610bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2b9350",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
